---
title: "error_finalviz"
output: html_document
---

#{.tabset}
```{r setup, include=FALSE, warning=FALSE, message=FALSE}

#Packages
library(tidyverse)
library(here)
library(RColorBrewer)
library(extrafont)

#Data
err_rep5u <- read_csv(file=file.path(here(),"/Results/error/error_updating_rep5_hcr30.csv"))
err_rep10u <- read_csv(file=file.path(here(),"/Results/error/error_updating_rep10_hcr30.csv"))
err_rep5c <- read_csv(file=file.path(here(),"/Results/error/error_constant_rep5_hcr30.csv"))
err_rep10c <- read_csv(file=file.path(here(),"/Results/error/error_constant_rep10_hcr30.csv"))
err_rep5c_p <- read_csv(file=file.path(here(),"/Results/error/error_constant_rep5_hcr30_p.csv")) #compare perceived to error

#Comparision of perfect management data
perfect <- read_csv(file=file.path(here(),"/Tests/perfect_management/csv_results/perfect_r0.1.csv"))
perfect_fishe <- read_csv(file=file.path(here(),"/Results/error/perfect_updating_rep5_hcr30.csv"))

```


##Constant Fmsy

Going to try understanding the break down of wrong decisions to look for interesting patterns:  

Steps:  
  - Create a column to track actions using the following criteria:  
      - If the manager made the correct decision --> correct 
      - If the manager made the wrong decision and should have cutback but increased fishing instead --> cutback  
      - If the manager made the wrong decision and should have closed the fishery but didn't --> should_closed  
      - If the manager made the wrong decision and closed the fishery but shouldn't have --> false_close  
      - If the manager made the wrong decision and cutback but could have increased fishing --> increase
      - If the fishery is closed (no decision was made) --> closed
  - Wrangle data to only include assessment years    
  - Group by actions at different error levels   
  - Calculate the proportion of different outcomes 
  
NOTE: Will not use this for final graphs - see next code chunk  
```{r wrangle-constant, include=FALSE}

#Add column to track if specific actions resulting from different decisions:  
rep5c_edit <- err_rep5c %>% 
  mutate(action = ifelse(correct_decision == "no" & ratio_cat == 2 & ratio_err_cat == 1, "cutback", 
                          ifelse(correct_decision == "no" & ratio_cat == 3, "should_close", 
                                 ifelse(correct_decision == "no" & ratio_cat == 2 & ratio_err_cat == 3, "false_close",
                                        ifelse(correct_decision == "no" & ratio_cat == 1, "increase",
                                               ifelse(correct_decision == "yes", "correct", "closed")))))) %>% 
  mutate(status = ifelse(f_ratio == 0, "closed", ifelse(b <= 1000, "over", "good"))) %>% 
  mutate(growth = ifelse(r_0 <= .3, "slow", ifelse(r_0 > .3 & r_0 <= .5, "medium", "fast")))
         

#Assessment years:
assess_5 <- seq(5,100,5)

#Group based on action and error:
prop_actions_c <- rep5c_edit %>%
  filter(year == 1 | year %in% assess_5) %>% 
  filter(status != "NA") %>% 
  group_by(error, action) %>% 
  tally() %>% 
  rename("count_5c" = n) %>% 
  spread(key = "action", value = "count_5c") %>% 
  mutate(wrong_decision = sum(cutback + false_close + increase + should_close)) %>% 
  mutate(total_assessments = sum(closed + correct + cutback + false_close + increase + should_close)) %>%
  mutate(prop_correct = correct / total_assessments) %>% 
  mutate(prop_false_close = false_close / total_assessments) %>% 
  mutate(prop_closed = closed / total_assessments)



prop_bad_c <- rep5c_edit %>% 
  filter(year == 1 | year %in% assess_5) %>%
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_5c" = n) %>% 
  spread(key = "correct_decision", value = "count_5c") %>% 
  mutate(total_decisions = sum(yes + no)) %>% 
  mutate(total_assessments = sum(yes + no + fail)) %>% 
  mutate(prop_wrong = no / total_decisions) %>% 
  mutate(prop_closed = fail / total_assessments)


#Compare these outcomes for the simulation that looks at percieved and error instead of actual fmsy and error 
prop_bad_p <- err_rep5c_p %>% 
  filter(year == 1 | year %in% assess_5) %>%
  group_by(error, correct_decision) %>% 
  tally() %>% 
  rename("count_5c" = n) %>% 
  spread(key = "correct_decision", value = "count_5c") %>% 
  mutate(total_decisions = sum(yes + no)) %>% 
  mutate(total_assessments = sum(yes + no + fail)) %>% 
  mutate(prop_wrong = no / total_decisions) %>% 
  mutate(prop_closed = fail / total_assessments)
#This makes SOOO much more sense - good job on figuring that out Chase!

```

This time use Chase's method of Year 100 overfished, good, closed. Proportion of bad outcomes is closed + overfished  

Use this code chunk for final graph!
```{r year100-constant, include=FALSE}
##Looking at outcomes only in year 100 
#First find proportion of bad outcomes in year 100 (fisheries closed + overfished)
prop_100_c <- rep5c_edit %>% 
  filter(year == 100) %>% 
  filter(status != "NA") %>% 
  group_by(error, status) %>% 
  tally() %>% 
  rename("count_5c" = n) %>% 
  spread(key = "status", value = "count_5c") %>% 
  mutate(simulations = sum(closed + good + over)) %>% 
  mutate(prop_over = over / simulations) %>% 
  mutate(prop_closed = closed / simulations) %>% 
  mutate(prop_bad = sum(over + closed) / simulations)


#For a bar graph with the columns by color you need a table that has error, then a variable "type" - over or closed, and then prop
over <- data.frame(error = prop_100_c$error, type = rep("over",3), prop = prop_100_c$prop_over, productivity = rep("constant", 3))
closed <- data.frame(error = prop_100_c$error, type = rep("closed", 3), prop = prop_100_c$prop_closed, productivity = rep("constant", 3))
graph_df <- rbind(over, closed)

```


```{r constant-graphs, echo=FALSE}
#Want to have error as a factor so that the graphs have a discrete x-axis:
graph_df$error <- as.factor(graph_df$error)


#Graph with prop bad outcomes in year 100 (overfished + closed):
prop_bad100_c <- ggplot(prop_100_c, aes(x = error, y = prop_bad)) +
  geom_col(position = "dodge", alpha = .7, fill = "#079EDF", width = 0.5) +
  theme_light()+
  coord_cartesian( ylim=c(0,.55), expand = FALSE ) +
  labs(title = "Error Assessments", x = "Error Amount (%)", y = "Proportion Closed/Overfished")+
  theme(axis.text.x=element_text(size=15), axis.text.y=element_text(size=15), plot.title = element_text(hjust = 0.5, face = "bold", size = 20), axis.title.x = element_text(face = "bold", size = 15), axis.title.y = element_text(face = "bold", size = 15),
        panel.background = element_rect(fill = "transparent",colour = NA),
        plot.background = element_rect(fill = "transparent",colour = NA)) +
  geom_text(aes(label = round(prop_bad, digits = 2)), position = position_stack(vjust = 0.75), size = 7)
prop_bad100_c

#ggsave(prop_bad100_c, filename = "error.png",  bg = "transparent")


##Try the other graph with the fill by type:
prop_graph <- ggplot(graph_df, aes(x=error, y=prop)) + 
  geom_col(aes(fill = type), alpha = 0.7)
prop_graph


```

##Constant vs. Updating Fmsy

For Test 4 we need to have a bar graph of proportion of bad outcomes for constant vs. updating fmsy   

First, wrangle data using the open, closed, overfished in year 100 and then graph both  

```{r year100-updating, include=FALSE}
prop_100_u <- err_rep5u %>% 
  filter(year == 100) %>% 
  mutate(status = ifelse(f_ratio == 0, "closed", ifelse(b <= 1000, "over", "good"))) %>% 
  mutate(growth = ifelse(r_0 <= .3, "slow", ifelse(r_0 > .3 & r_0 <= .5, "medium", "fast"))) %>% 
  filter(status != "NA") %>% 
  group_by(error, status) %>% 
  tally() %>% 
  rename("count_5c" = n) %>% 
  spread(key = "status", value = "count_5c") %>% 
  mutate(simulations = sum(closed + good)) %>% 
  mutate(prop_bad = closed / simulations) 

##Create the graph data frame - constant then updating and combine:
graph_c <- data.frame(error = prop_100_c$error, prop = prop_100_c$prop_bad, productivity = rep("constant", 3))
graph_u <- data.frame(error = prop_100_u$error, prop = prop_100_u$prop_bad, productivity = rep("updating", 3))
graph_both <- rbind(graph_c, graph_u)

#Combine using the constant (graph_df) from above for the second fill by type graph:
graph_u2 <- data.frame(error = prop_100_u$error, type = rep("closed", 3), prop = prop_100_u$prop_bad, productivity = rep("updating", 3))
graph_both2 <- rbind(graph_df, graph_u2)
graph_both2$error <- as.factor(graph_both2$error)
```

```{r combined-graph, echo=FALSE}
#Want to have error as a factor so that the graphs have a discrete x-axis:
graph_both$error <- as.factor(graph_both$error)

prop_100_both <- ggplot(graph_both, aes(x=error, y = prop, fill = productivity)) + 
  geom_col(position = "dodge", alpha = .7) +
  scale_fill_manual(values = c("#079EDF", "#B8CE55"), name = "Fmsy \n(Productivity)", labels = c("Constant", "Updating"))+
  theme_light()+
  coord_cartesian( ylim=c(0,.55), expand = FALSE ) +
  labs(title = "Error Assessments", x = "Error Amount (%)", y = "Proportion Closed/Overfished")+
  theme(axis.text.x=element_text(size=15), axis.text.y=element_text(size=15), plot.title = element_text(hjust = 0.5, face = "bold", size = 20), axis.title.x = element_text(face = "bold", size = 15), axis.title.y = element_text(face = "bold", size = 15), legend.title.align=0.5, panel.background = element_rect(fill = "transparent",colour = NA), plot.background = element_rect(fill = "transparent",colour = NA), legend.title=element_text(size=15), 
    legend.text=element_text(size=12),legend.key = element_rect(fill = "transparent", colour = "transparent")) +
  geom_text(aes(label = round(prop_bad, digits = 2)), position = position_dodge(0.9), vjust = 2, size = 5)
prop_100_both

#ggsave(prop_100_both, filename = "error_both.png",  bg = "transparent")

##Try the other graph with the fill by type:
prop_graph_both <- ggplot(graph_both2, aes(x=error, y=prop)) + 
  geom_col(aes(fill = productivity), position = "dodge", alpha = 0.7)
prop_graph_both

##Okay this is significantly harder... if we fill by productivity to distinguish between constant and updating we can't also fill by over/closed. The udpating fmsy one has no over it's only closed. Not sure if there's a way around this

```

